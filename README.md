Descri√ß√£o do DERSO

Este reposit√≥rio apresenta um pipeline completo de engenharia de dados utilizando Apache Airflow em ambiente on-premise (Databricks local), com o objetivo de orquestrar a ingest√£o, transforma√ß√£o, modelagem e disponibiliza√ß√£o de dados em m√∫ltiplas camadas.

O projeto utiliza 3 ou mais tabelas relacionadas ao mesmo dom√≠nio tem√°tico (ex.: datasets do Kaggle, dados gerados pelo GPT, etc.), demonstrando o processo de ponta a ponta de um fluxo moderno de dados. Todo o desenvolvimento √© controlado por versionamento via GitHub, utilizando commits estruturados e documenta√ß√£o adequada.

Principais Componentes
Orquestra√ß√£o

Execu√ß√£o via Apache Airflow

DAGs criadas para controlar depend√™ncias entre etapas

Monitoramento e reprocessamento de tarefas

Processamento de Dados

Execu√ß√£o local com Databricks (on-premise)

Camadas definidas em arquitetura estilo medallion:

Landing

Bronze

Silver

Gold

Modelagem Dimensional

Estrutura em Fato e Dimens√£o

Aplica√ß√£o de boas pr√°ticas de Data Warehouse

Ajustes para consultas anal√≠ticas

Dataset

Conjunto de tabelas do mesmo assunto/tema (econ√¥mico, esportivo, m√≠dia, etc.)

Possibilidade de expans√£o (mais tabelas/dominios)

Governan√ßa e Versionamento

Controle via Git + GitHub

Commits granulares e descritivos

Issue tracking e milestones

Documenta√ß√£o

README com explica√ß√£o do cen√°rio

Stack utilizada

Como executar o projeto

Fluxo das etapas e exemplos

Objetivos de Aprendizado

Este projeto busca demonstrar compet√™ncias em:

‚úî Orquestra√ß√£o de pipelines batch
‚úî ETL/ELT completo do zero
‚úî Boas pr√°ticas de engenharia de dados
‚úî Modelagem Dimensional
‚úî Organiza√ß√£o e controle de versionamento
‚úî Documenta√ß√£o e padroniza√ß√£o de reposit√≥rio

Timeline Estimada

üóì Dura√ß√£o total: 20 dias
üìÖ Prazo planejado: at√© 09/02
